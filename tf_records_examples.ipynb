{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we shall see how to convert large `NumPy` arrays to `.tfrecords` and train a model.\n",
    "* We will also compare the speed of training between loading a large `NumPy` array directly into the model vs streaming the data into the model using `.tfrecord`. \n",
    "\n",
    "* [Source1](https://datamadness.github.io/tensorflow_estimator_large_dataset_feed)\n",
    "* [Source2](https://www.tensorflow.org/tutorials/load_data/tfrecord#walkthrough_reading_and_writing_image_data)\n",
    "* [Source3](https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564)\n",
    "* [Source4](https://medium.com/@prasad.pai/how-to-use-dataset-and-iterators-in-tensorflow-with-code-samples-3bb98b6b74ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import sys, pickle, os\n",
    "import h5py, time, inspect\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a large `NumPy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/emnist_train_x.h5'\n",
    "with h5py.File(filename, 'r') as hf:\n",
    "    train_x = list(hf['pool1_spike_features'][:])\n",
    "\n",
    "filename = 'data/emnist_test_x.h5'\n",
    "with h5py.File(filename, 'r') as hf:\n",
    "    test_x = list(hf['pool1_spike_features'][:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/emnist_train_y.pkl'\n",
    "filehandle = open(filename, 'rb')\n",
    "train_y = pickle.load(filehandle).tolist()\n",
    "\n",
    "filename = 'data/emnist_test_y.pkl'\n",
    "filehandle = open(filename, 'rb')\n",
    "test_y = pickle.load(filehandle).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `.tfrecord` in `Tensorflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function that return list of floats/bytes/ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _byte_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def array_bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value.tobytes()))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def array_floats_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value.flatten()))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_object(observation_id=0, data_x=None, data_y=None):\n",
    "    #print(train_y[observation_id])\n",
    "    feature = {\n",
    "        'label': _int64_feature(data_y[observation_id]),\n",
    "        'image_raw': array_floats_feature(data_x[observation_id]),\n",
    "  }\n",
    "    example_obj = tf.train.Example(features=tf.train.Features(feature=feature)) \n",
    "    return example_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing a single Image\n",
    "* `get_example_object` function returns a proto buffer kind of object and we then serialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/visionteam/.local/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fa84d23de37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_example_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mserialized_example_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-231222bea9eb>\u001b[0m in \u001b[0;36mget_example_object\u001b[0;34m(observation_id, data_x, data_y)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print(train_y[observation_id])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     feature = {\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_int64_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m'image_raw'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_floats_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   }\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "example_obj = get_example_object(0)\n",
    "print(example_obj)\n",
    "serialized_example_obj = example_obj.SerializeToString()\n",
    "print()\n",
    "print()\n",
    "serialized_example_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_example_obj=tf.train.Example.FromString(serialized_example_obj)\n",
    "parsed_example_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tf.io.TFRecordWriter()` takes same `compression_type` argument as `tf.data.TFRecordDataset`.\n",
    "* [Source](https://github.com/tensorflow/tensorflow/issues/32075#issuecomment-528117457)\n",
    "* [tf.io.TFRecordWriter](https://www.tensorflow.org/api_docs/python/tf/io/TFRecordWriter)\n",
    "* [tf.data.TFRecordDataset](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)\n",
    "* If you don't use compression your .tfrecords files might end up much larger than original dataset. If you are storing .tfrecords for images then simply read the image file with inbuilt compression `image_string = open(filename, 'rb').read()` and store it, [see](https://github.com/tensorflow/tensorflow/issues/9675#issuecomment-302745553)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.TFRecordOptions.compression_type_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make `.tfrecord` for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "num_partitions = 10\n",
    "partitions = np.linspace(0,len(train_x), num_partitions+1)\n",
    "partitions[-1] -= 1\n",
    "partitions = partitions.astype(np.int32).tolist()\n",
    "print(partitions)\n",
    "for partition_id in range(num_partitions):\n",
    "    with tf.io.TFRecordWriter('tfrecords/EMNIST_train_strings_' + str(partition_id) + '.tfrecord', 'GZIP') as tfwriter:\n",
    "        for observation_id in range(partitions[partition_id],partitions[partition_id+1]):\n",
    "            example_obj = get_example_object(observation_id, data_x=train_x, data_y=train_y)\n",
    "            tfwriter.write(example_obj.SerializeToString())\n",
    "print('Time taken:{}'.format(time.time()-t1))  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make `.tfrecord` for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "num_partitions = 2\n",
    "partitions = np.linspace(0,len(test_x), num_partitions+1)\n",
    "partitions[-1] -= 1\n",
    "partitions = partitions.astype(np.int32).tolist()\n",
    "print(partitions)\n",
    "for partition_id in range(num_partitions):\n",
    "    with tf.io.TFRecordWriter('tfrecords/EMNIST_test_strings_' + str(partition_id) + '.tfrecord', 'GZIP') as tfwriter:\n",
    "        for observation_id in range(partitions[partition_id],partitions[partition_id+1]):\n",
    "            example_obj = get_example_object(observation_id, data_x=test_x, data_y=test_y)\n",
    "            tfwriter.write(example_obj.SerializeToString())\n",
    "print('Time taken:{}'.format(time.time()-t1))  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the raw dataset .tfrecord file\n",
    "* `raw_data` is Tensor with some metadata\n",
    "* `example` is a loaded string that has the protocol buffer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['tfrecords/EMNIST_train_strings_0.tfrecord']\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP',num_parallel_reads=1)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Only works in eager mode (enable it from imports section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_data in raw_dataset.take(1):\n",
    "    print(repr(raw_data))\n",
    "    print()\n",
    "    print()\n",
    "    example = tf.train.Example.FromString(raw_data.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example.features.feature['image_raw'].float_list.value[0])\n",
    "print(example.features.feature['label'].int64_list.value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing using `tf.FixedLenFeature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([3630], tf.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Original image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parsed Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.io.parse_single_example(raw_data, image_feature_description)['image_raw'].numpy().sum())\n",
    "print(tf.io.parse_single_example(raw_data, image_feature_description)['label']).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing using `tf.VarLenFeature()`\n",
    "* Notice that `tf.io.VarLenFeature` returned a sparse tensor that needs to be converted to a dense one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.VarLenFeature(tf.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parsed Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor = tf.io.parse_single_example(raw_data, image_feature_description)['image_raw']\n",
    "dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "print(dense_tensor.numpy().sum())\n",
    "print(tf.io.parse_single_example(raw_data, image_feature_description)['label']).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing all the `.tfrecords` and make an iterable dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    image_feature_description = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(record, image_feature_description)\n",
    "    \n",
    "    image = parsed['image_raw']\n",
    "    image = tf.sparse.to_dense(image,default_value = 0)\n",
    "    label = tf.cast(parsed[\"label\"], tf.int32)\n",
    "    \n",
    "    #return {\"image_data\": image}, label\n",
    "    return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using `.tfrecords` and `tf.keras.model.fit`\n",
    "* Load `.tfrecords` for the training data\n",
    "* See more about [shuffle_buffer_size](https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path='', shuffle_buffer_size=None, batch_size=None, compression='GZIP'):\n",
    "    filenames = [file for file in os.listdir(os.path.join(os.getcwd(), path)) if file.endswith('.tfrecord')]\n",
    "    filenames = [os.path.join(path, file) for file in filenames]\n",
    "    print('.tfrecord files:{}'.format(filenames))\n",
    "    raw_image_dataset = tf.data.TFRecordDataset(filenames, compression_type=compression)\n",
    "    print('\\n raw data:{}'.format(raw_image_dataset))\n",
    "    parsed_image_dataset = raw_image_dataset.map(parser)\n",
    "    print('\\n parsed data:{}'.format(parsed_image_dataset))\n",
    "    final_dataset = parsed_image_dataset.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "    print('\\n final dataset:{}'.format(final_dataset))\n",
    "\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take 10 images and inspect but only works in eager mode (enable it from imports section)\n",
    "\n",
    "`for item in parsed_image_dataset.take(10):\n",
    "    print\n",
    "    print('Image Data')\n",
    "    print(item[0])\n",
    "    print(item[0].numpy().sum())\n",
    "    print\n",
    "    print('Label Data')\n",
    "    print(item[1])\n",
    "    print(item[1].numpy())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple FCN with the loaded and parsed `.tfrecord` files\n",
    "* [Source](https://www.tensorflow.org/tutorials/load_data/numpy)\n",
    "\n",
    "* Setup the dataset\n",
    "* Try multiplying the `SHUFFLE_BUFFER_SIZE` with `10 or 100` and see the effects on training time and GPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".tfrecord files:['tfrecords/train/EMNIST_train_strings_4.tfrecord', 'tfrecords/train/EMNIST_train_strings_9.tfrecord', 'tfrecords/train/EMNIST_train_strings_6.tfrecord', 'tfrecords/train/EMNIST_train_strings_3.tfrecord', 'tfrecords/train/EMNIST_train_strings_5.tfrecord', 'tfrecords/train/EMNIST_train_strings_2.tfrecord', 'tfrecords/train/EMNIST_train_strings_0.tfrecord', 'tfrecords/train/EMNIST_train_strings_8.tfrecord', 'tfrecords/train/EMNIST_train_strings_7.tfrecord', 'tfrecords/train/EMNIST_train_strings_1.tfrecord']\n",
      "\n",
      " raw data:<TFRecordDatasetV1 shapes: (), types: tf.string>\n",
      "\n",
      " parsed data:<DatasetV1Adapter shapes: ((?,), ()), types: (tf.float32, tf.int32)>\n",
      "\n",
      " final dataset:<DatasetV1Adapter shapes: ((?, ?), (?,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE**2\n",
    "train_dataset = load_dataset('tfrecords/train', SHUFFLE_BUFFER_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def smol_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1500, input_dim=3630, activation='relu'),\n",
    "        tf.keras.layers.Dense(47)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.005),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 1500)              5446500   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 47)                70547     \n",
      "=================================================================\n",
      "Total params: 5,517,047\n",
      "Trainable params: 5,517,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on None steps\n",
      "Epoch 1/3\n",
      "3525/3525 [==============================] - 31s 9ms/step - loss: 1.5541 - sparse_categorical_accuracy: 0.643980 - sparse_categorical_accurac - 30s 9ms/step - l\n",
      "Epoch 2/3\n",
      "3525/3525 [==============================] - 27s 8ms/step - loss: 1.2151 - sparse_categorical_accuracy: 0.7099\n",
      "Epoch 3/3\n",
      "3525/3525 [==============================] - 26s 7ms/step - loss: 1.1325 - sparse_categorical_accuracy: 0.7284\n"
     ]
    }
   ],
   "source": [
    "model = smol_model()\n",
    "model.summary()\n",
    "history = model.fit(train_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".tfrecord files:['tfrecords/test/EMNIST_test_strings_0.tfrecord', 'tfrecords/test/EMNIST_test_strings_1.tfrecord']\n",
      "\n",
      " raw data:<TFRecordDatasetV1 shapes: (), types: tf.string>\n",
      "\n",
      " parsed data:<DatasetV1Adapter shapes: ((?,), ()), types: (tf.float32, tf.int32)>\n",
      "\n",
      " final dataset:<DatasetV1Adapter shapes: ((?, ?), (?,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset('tfrecords/test', SHUFFLE_BUFFER_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    588/Unknown - 4s 7ms/step - loss: 1.5163 - sparse_categorical_accuracy: 0.7154"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.516273353122124, 0.7154104]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train directly using the large `NumPy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112799,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112799, 3630)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1500)              5446500   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 47)                70547     \n",
      "=================================================================\n",
      "Total params: 5,517,047\n",
      "Trainable params: 5,517,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 112799 samples\n",
      "Epoch 1/3\n",
      "112799/112799 [==============================] - 9s 79us/sample - loss: 1.5267 - sparse_categorical_accuracy: 0.6428\n",
      "Epoch 2/3\n",
      "112799/112799 [==============================] - 9s 77us/sample - loss: 1.2117 - sparse_categorical_accuracy: 0.7062\n",
      "Epoch 3/3\n",
      "112799/112799 [==============================] - 8s 75us/sample - loss: 1.1141 - sparse_categorical_accuracy: 0.7297\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "model = smol_model()\n",
    "model.summary()\n",
    "history = model.fit(np.array(train_x),np.array(train_y), epochs=3, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "18800/18800 [==============================] - 0s 14us/sample - loss: 1.5333 - sparse_categorical_accuracy: 0.6971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5333495140075684, 0.69712764]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(test_x), np.array(test_y), batch_size=len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly storing `2D NumPy` arrays\n",
    "* `Tensorflow` TFRecords documentation file suggests storing images in serial strings with some metadata (Height, width, channels etc as extra features). What if you have some large 2D `NumPy` arrays that you want to store them as it is without flattening like we did above. \n",
    "* [Source](https://stackoverflow.com/questions/47861084/how-to-store-numpy-arrays-as-tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "324.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

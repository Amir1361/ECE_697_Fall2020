{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Course Instructor`: **John Chiasson**\n",
    "\n",
    "`Author (TA)`: **Ruthvik Vaila**\n",
    "\n",
    "* In this notebook we shall see how to parallellize tfrecordization.\n",
    "* Tested on `Python 3.7.5` with `Tensorflow 1.15.0` and `Keras 2.2.4`. \n",
    "* Tested on `Python 2.7.17` with `Tensorflow 1.15.3` and `Keras 2.2.4`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py, pickle, inspect, functools, os, shutil, sys\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import tfrecords_worker as tfwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.5 (default, Nov  7 2019, 10:50:52) \\n[GCC 8.3.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a large `NumPy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:(112799, 3630)\n",
      "Test data shape:(18800, 3630)\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/emnist_train_x.h5'\n",
    "with h5py.File(filename, 'r') as hf:\n",
    "    train_x = hf['pool1_spike_features'][:]\n",
    "\n",
    "filename = 'data/emnist_test_x.h5'\n",
    "with h5py.File(filename, 'r') as hf:\n",
    "    test_x = hf['pool1_spike_features'][:]\n",
    "\n",
    "print('Train data shape:{}'.format(train_x.shape))\n",
    "print('Test data shape:{}'.format(test_x.shape))\n",
    "\n",
    "train_x = list(train_x) #convert 2D numpy array to a list of 1D numpy arrays \n",
    "test_x = list(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape:(112799,)\n",
      "Test labels shape:(18800,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/emnist_train_y.pkl'\n",
    "filehandle = open(filename, 'rb')\n",
    "train_y = pickle.load(filehandle)\n",
    "filehandle.close()\n",
    "\n",
    "filename = 'data/emnist_test_y.pkl'\n",
    "filehandle = open(filename, 'rb')\n",
    "test_y = pickle.load(filehandle)\n",
    "filehandle.close()\n",
    "\n",
    "print('Train labels shape:{}'.format(train_y.shape))\n",
    "print('Test labels shape:{}'.format(test_y.shape))\n",
    "\n",
    "train_y = train_y.tolist() #convert 2D numpy array to a list of 1D numpy arrays \n",
    "test_y = test_y.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `inspect` to examine the arguments of `tfwk.worker` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visionteam/python37_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['partitions', 'train_x', 'train_y', 'filename']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getargspec(tfwk.worker)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [0, 5639]), (1, [5639, 11279]), (2, [11279, 16919]), (3, [16919, 22559]), (4, [22559, 28199]), (5, [28199, 33839]), (6, [33839, 39479]), (7, [39479, 45119]), (8, [45119, 50759]), (9, [50759, 56399]), (10, [56399, 62039]), (11, [62039, 67679]), (12, [67679, 73319]), (13, [73319, 78959]), (14, [78959, 84599]), (15, [84599, 90239]), (16, [90239, 95879]), (17, [95879, 101519]), (18, [101519, 107159]), (19, [107159, 112798])]\n"
     ]
    }
   ],
   "source": [
    "num_partitions = 20\n",
    "partitions = np.linspace(0,len(train_x), num_partitions+1)\n",
    "partitions[-1] -= 1\n",
    "partitions = partitions.astype(np.int32).tolist()\n",
    "#print(partitions)\n",
    "\n",
    "partitions = np.repeat(partitions, 2)[1:-1].tolist()\n",
    "#print(partitions)\n",
    "\n",
    "iter_lists = np.split(np.array(partitions), num_partitions)\n",
    "iter_lists = [item.tolist() for item in iter_lists]\n",
    "#print(iter_lists)\n",
    "\n",
    "iter_lists = list(enumerate(iter_lists))\n",
    "print(iter_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating `.tfrecords` serially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for serial process:83.82524633407593\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "folder_name = 'parallel_tfrecords/'\n",
    "if os.path.exists(folder_name):\n",
    "    shutil.rmtree(folder_name)\n",
    "os.mkdir(folder_name)\n",
    "filename=folder_name+'EMNIST_train_strings_'\n",
    "worker = functools.partial(tfwk.worker, train_x=train_x, train_y=train_y, filename=filename)\n",
    "for item in iter_lists:\n",
    "    worker(item)\n",
    "print('Time taken for serial process:{}'.format(time.time()-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating `.tfrecords` parallelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for serial process:44.98908305168152\n",
      "Multiprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    t1 = time.time()\n",
    "    folder_name = 'parallel_tfrecords/'\n",
    "    if os.path.exists(folder_name):\n",
    "        shutil.rmtree(folder_name)\n",
    "    os.mkdir(folder_name)\n",
    "    filename=folder_name+'EMNIST_train_strings_'\n",
    "    worker = functools.partial(tfwk.worker, train_x=train_x, train_y=train_y, filename=filename)\n",
    "    num_process = 6\n",
    "    pool = mp.Pool(num_process)\n",
    "    pool_handle = pool.map_async(worker, iter_lists)\n",
    "    pool_handle.get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Time taken for serial process:{}'.format(time.time()-t1))\n",
    "    print('Multiprocessing Done!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37_env",
   "language": "python",
   "name": "python37_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
